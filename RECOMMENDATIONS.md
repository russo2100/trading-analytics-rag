# üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—é —Ä–∞–±–æ—Ç—ã

## üìã –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∑–∞–¥–∞—á–∏

### üî¥ –ö–†–ò–¢–ò–ß–ù–û - –°–¥–µ–ª–∞—Ç—å —Å–µ–≥–æ–¥–Ω—è

#### 1. –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å
**–ü—Ä–æ–±–ª–µ–º–∞**: –í–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å –Ω–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω, –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è `data/vector_index/` –ø—É—Å—Ç–∞.

**–†–µ—à–µ–Ω–∏–µ**:
```bash
# –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
venv\Scripts\activate

# –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∏–Ω–¥–µ–∫—Å –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
python scripts/build_vector_index.py

# –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:
# - –°–æ–∑–¥–∞–Ω–∏–µ FAISS –∏–Ω–¥–µ–∫—Å–∞
# - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è 1,041 —Å–æ–±—ã—Ç–∏–π
# - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ data/vector_index/
```
e
**–ü—Ä–æ–±–ª–µ–º–∞**: –¢–∞–±–ª–∏—Ü–∞ `events` –ø—É—Å—Ç–∞ (RAG —Å–æ–±—ã—Ç–∏—è –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã).

**–†–µ—à–µ–Ω–∏–µ**:
```bash
# –°–Ω–∞—á–∞–ª–∞ –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ–±—ã—Ç–∏—è –∏–∑ trading_events –≤ events
# –°–æ–∑–¥–∞—Ç—å —Å–∫—Ä–∏–ø—Ç –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–æ–≤—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
```

#### 2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
**–ü—Ä–æ–±–ª–µ–º–∞**: `ModuleNotFoundError: No module named 'faiss'`

**–†–µ—à–µ–Ω–∏–µ**:
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —É—Å—Ç–∞–Ω–æ–≤–∫—É –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install -r requirements.txt

# –ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã —Å faiss-cpu, –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å:
pip install faiss-cpu --no-cache-dir

# –î–ª—è GPU –≤–µ—Ä—Å–∏–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å CUDA):
pip install faiss-gpu
```

---

### üü° –í–ê–ñ–ù–û - –°–¥–µ–ª–∞—Ç—å –Ω–∞ —ç—Ç–æ–π –Ω–µ–¥–µ–ª–µ

#### 3. –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤

**EIA Storage Reports**:
```python
# –°–æ–∑–¥–∞—Ç—å —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ EIA –¥–∞–Ω–Ω—ã—Ö
# scripts/ingest_eia_data.py

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å EIA API:
# https://www.eia.gov/opendata/
```

**Weather Data**:
```python
# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å weather API
# scripts/ingest_weather_data.py
```

**News Articles**:
```python
# –ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
# scripts/ingest_news.py
```

#### 4. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫

```bash
# –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
python scripts/test_vector_search.py --interactive

# –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã:
# - "trading decision buy"
# - "market price RSI indicator"
# - "profit and loss"
# - "AI signal confidence"
```

#### 5. –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Hybrid Search

**–§–∞–π–ª**: `src/layer3_retrieval/hybrid_search.py`

```python
class HybridSearch:
    def __init__(self, vector_store, metadata_store):
        self.vector_store = vector_store
        self.metadata_store = metadata_store
        
    def search(self, query, top_k=10):
        # 1. BM25 search (SQLite FTS5)
        bm25_results = self._bm25_search(query, top_k * 2)
        
        # 2. Dense search (FAISS)
        dense_results = self.vector_store.search(query, top_k * 2)
        
        # 3. Reciprocal Rank Fusion
        fused_results = self._rrf_fusion(bm25_results, dense_results)
        
        return fused_results[:top_k]
```

---

### üü¢ –ñ–ï–õ–ê–¢–ï–õ–¨–ù–û - –°–¥–µ–ª–∞—Ç—å –≤ —ç—Ç–æ–º –º–µ—Å—è—Ü–µ

#### 6. –°–æ–∑–¥–∞—Ç—å Evaluation Dataset

**–§–∞–π–ª**: `data/eval/gold_qa.jsonl`

```json
{"question": "–ö–∞–∫–æ–µ —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–∏–Ω—è–ª –±–æ—Ç 30 —è–Ω–≤–∞—Ä—è –≤ 11:18?", "answer": "...", "event_ids": ["..."]}
{"question": "–ö–∞–∫–æ–π –±—ã–ª RSI –Ω–∞ –º–æ–º–µ–Ω—Ç –ø–æ–∫—É–ø–∫–∏?", "answer": "...", "event_ids": ["..."]}
{"question": "–°–∫–æ–ª—å–∫–æ —Å–¥–µ–ª–æ–∫ –±—ã–ª–æ —Å–æ–≤–µ—Ä—à–µ–Ω–æ 29 —è–Ω–≤–∞—Ä—è?", "answer": "19", "event_ids": ["..."]}
```

**–°–∫—Ä–∏–ø—Ç**: `scripts/run_eval.py`

```python
# –ú–µ—Ç—Ä–∏–∫–∏:
# - Precision@K
# - Recall@K
# - MRR (Mean Reciprocal Rank)
# - NDCG (Normalized Discounted Cumulative Gain)
```

#### 7. –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å LLM

**–§–∞–π–ª**: `src/layer4_generation/answer_generator.py`

```python
from openai import OpenAI

class AnswerGenerator:
    def __init__(self):
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=settings.openrouter_api_key
        )
    
    def generate(self, query, context):
        prompt = self._build_prompt(query, context)
        response = self.client.chat.completions.create(
            model=settings.openrouter_model,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
```

#### 8. –î–æ–±–∞–≤–∏—Ç—å Reranking

**–§–∞–π–ª**: `src/layer3_retrieval/reranker.py`

```python
from sentence_transformers import CrossEncoder

class Reranker:
    def __init__(self):
        self.model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
    
    def rerank(self, query, results, top_k=10):
        # –°–æ–∑–¥–∞—Ç—å –ø–∞—Ä—ã (query, document)
        pairs = [(query, r['text']) for r in results]
        
        # –ü–æ–ª—É—á–∏—Ç—å scores
        scores = self.model.predict(pairs)
        
        # –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –≤–µ—Ä–Ω—É—Ç—å top-K
        reranked = sorted(
            zip(results, scores), 
            key=lambda x: x[1], 
            reverse=True
        )
        return [r for r, s in reranked[:top_k]]
```

---

## üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —É–ª—É—á—à–µ–Ω–∏—è

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

#### 1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å IVF –∏–Ω–¥–µ–∫—Å –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö
```python
# –í–º–µ—Å—Ç–æ IndexFlatL2 –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å IndexIVFFlat
# –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞ –Ω–∞ –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö

import faiss

# –û–±—É—á–∏—Ç—å quantizer
quantizer = faiss.IndexFlatL2(dimension)
index = faiss.IndexIVFFlat(quantizer, dimension, nlist=100)

# –û–±—É—á–∏—Ç—å –Ω–∞ –¥–∞–Ω–Ω—ã—Ö
index.train(embeddings)
index.add(embeddings)
```

#### 2. –î–æ–±–∞–≤–∏—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
```python
# src/layer2_storage/cache.py

from functools import lru_cache
import redis

class QueryCache:
    def __init__(self):
        self.redis_client = redis.Redis() if settings.use_redis else None
    
    @lru_cache(maxsize=1000)
    def get_or_compute(self, query, compute_fn):
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫—ç—à
        if self.redis_client:
            cached = self.redis_client.get(query)
            if cached:
                return json.loads(cached)
        
        # –í—ã—á–∏—Å–ª–∏—Ç—å
        result = compute_fn(query)
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∫—ç—à
        if self.redis_client:
            self.redis_client.setex(query, 3600, json.dumps(result))
        
        return result
```

#### 3. Batch processing –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
```python
# –£–∂–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –≤ VectorStore.add_events()
# batch_size=32 –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
```

---

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

### 1. –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ query_stats

```python
# –ü—Ä–∏ –∫–∞–∂–¥–æ–º –∑–∞–ø—Ä–æ—Å–µ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å:
# - query_text
# - result_count
# - latency_ms
# - cache_hit

def log_query_stats(query, results, latency, cache_hit):
    cursor.execute("""
        INSERT INTO query_stats 
        (query_text, result_count, latency_ms, cache_hit)
        VALUES (?, ?, ?, ?)
    """, (query, len(results), latency, cache_hit))
```

### 2. –°–æ–∑–¥–∞—Ç—å dashboard –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞

```python
# scripts/show_stats.py

import sqlite3
import pandas as pd

def show_query_stats():
    conn = sqlite3.connect('data/metadata.db')
    
    # –¢–æ–ø –∑–∞–ø—Ä–æ—Å–æ–≤
    df = pd.read_sql("""
        SELECT query_text, COUNT(*) as count, AVG(latency_ms) as avg_latency
        FROM query_stats
        GROUP BY query_text
        ORDER BY count DESC
        LIMIT 10
    """, conn)
    
    print(df)
```

---

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### 1. –î–æ–±–∞–≤–∏—Ç—å integration —Ç–µ—Å—Ç—ã

**–§–∞–π–ª**: `tests/integration/test_rag_pipeline.py`

```python
def test_end_to_end_rag():
    # 1. –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
    # 2. –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∏–Ω–¥–µ–∫—Å
    # 3. –í—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å
    # 4. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    
    query = "–ö–∞–∫–æ–µ —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–∏–Ω—è–ª –±–æ—Ç?"
    results = rag_pipeline.search(query)
    
    assert len(results) > 0
    assert results[0]['score'] > 0.7
```

### 2. –î–æ–±–∞–≤–∏—Ç—å benchmark —Ç–µ—Å—Ç—ã

**–§–∞–π–ª**: `tests/benchmark/test_performance.py`

```python
import time

def test_search_performance():
    # –ò–∑–º–µ—Ä–∏—Ç—å –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞
    start = time.time()
    results = vector_store.search("test query", top_k=100)
    latency = (time.time() - start) * 1000
    
    # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å < 100ms –¥–ª—è 1000 –≤–µ–∫—Ç–æ—Ä–æ–≤
    assert latency < 100
```

---

## üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

### 1. –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

**–§–∞–π–ª**: `docs/examples.md`

```markdown
# –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

## –ë–∞–∑–æ–≤—ã–π –ø–æ–∏—Å–∫
```python
from src.layer2_storage.vector_store import VectorStore

vs = VectorStore()
vs.load()

results = vs.search("trading decision", top_k=5)
for r in results:
    print(f"{r['event_id']}: {r['score']:.3f}")
```

## –ü–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
```python
results = vs.search(
    "market price",
    top_k=10,
    filter_metadata={'source': 'logs'}
)
```
```

### 2. –°–æ–∑–¥–∞—Ç—å API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é

**–§–∞–π–ª**: `docs/api.md`

```markdown
# API Reference

## VectorStore

### Methods

#### `add_events(event_ids, texts, metadata)`
–î–æ–±–∞–≤–∏—Ç—å —Å–æ–±—ã—Ç–∏—è –≤ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å.

**Parameters:**
- `event_ids` (List[str]): –°–ø–∏—Å–æ–∫ ID —Å–æ–±—ã—Ç–∏–π
- `texts` (List[str]): –¢–µ–∫—Å—Ç—ã –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
- `metadata` (List[Dict]): –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

**Returns:** None

**Example:**
```python
vs.add_events(
    ['e1', 'e2'],
    ['text 1', 'text 2'],
    [{'source': 'logs'}, {'source': 'eia'}]
)
```
```

---

## üöÄ Deployment

### 1. –°–æ–∑–¥–∞—Ç—å FastAPI —Å–µ—Ä–≤–∏—Å

**–§–∞–π–ª**: `src/api/main.py`

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class SearchRequest(BaseModel):
    query: str
    top_k: int = 10

@app.post("/search")
async def search(request: SearchRequest):
    results = vector_store.search(request.query, request.top_k)
    return {"results": results}
```

### 2. –î–æ–±–∞–≤–∏—Ç—å Docker

**–§–∞–π–ª**: `Dockerfile`

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**–§–∞–π–ª**: `docker-compose.yml`

```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
    environment:
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
```

---

## üìà Roadmap

### –ù–µ–¥–µ–ª—è 1 (—Ç–µ–∫—É—â–∞—è)
- [x] –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å
- [x] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫
- [ ] –ó–∞–≥—Ä—É–∑–∏—Ç—å EIA –¥–∞–Ω–Ω—ã–µ

### –ù–µ–¥–µ–ª—è 2
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å hybrid search
- [ ] –î–æ–±–∞–≤–∏—Ç—å reranking
- [ ] –°–æ–∑–¥–∞—Ç—å eval dataset

### –ù–µ–¥–µ–ª—è 3
- [ ] –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å LLM
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å RAG pipeline
- [ ] –î–æ–±–∞–≤–∏—Ç—å citation tracking

### –ù–µ–¥–µ–ª—è 4
- [ ] –°–æ–∑–¥–∞—Ç—å FastAPI —Å–µ—Ä–≤–∏—Å
- [ ] –î–æ–±–∞–≤–∏—Ç—å Docker
- [ ] –ù–∞–ø–∏—Å–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é

---

## üí° –°–æ–≤–µ—Ç—ã

### Best Practices

1. **–í—Å–µ–≥–¥–∞ —Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –Ω–∞ –º–∞–ª–µ–Ω—å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å–Ω–∞—á–∞–ª–∞**
   ```bash
   python scripts/build_vector_index.py --limit 100
   ```

2. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏**
   ```python
   import logging
   logging.basicConfig(level=logging.DEBUG)
   ```

3. **–°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã**
   ```python
   # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–Ω–¥–µ–∫—Å –ø–æ—Å–ª–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è
   vector_store.save()
   ```

4. **–ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å**
   ```python
   import time
   start = time.time()
   results = vector_store.search(query)
   print(f"Search took {time.time() - start:.3f}s")
   ```

### –ß–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏

1. **–ó–∞–±—ã—Ç—å –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å venv**
   ```bash
   # Windows
   venv\Scripts\activate
   
   # Linux/Mac
   source venv/bin/activate
   ```

2. **–ù–µ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏**
   ```bash
   pip install -r requirements.txt
   ```

3. **–ù–µ —Å–æ–∑–¥–∞—Ç—å .env —Ñ–∞–π–ª**
   ```bash
   cp .env.example .env
   # –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å .env –∏ –¥–æ–±–∞–≤–∏—Ç—å API –∫–ª—é—á–∏
   ```

---

## üéì –†–µ—Å—É—Ä—Å—ã –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è

### RAG Systems
- [LangChain Documentation](https://python.langchain.com/)
- [LlamaIndex Guide](https://docs.llamaindex.ai/)
- [FAISS Tutorial](https://github.com/facebookresearch/faiss/wiki)

### Evaluation
- [Ragas Framework](https://docs.ragas.io/)
- [BEIR Benchmark](https://github.com/beir-cellar/beir)

### LLM Integration
- [OpenRouter Docs](https://openrouter.ai/docs)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)

---

**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ**: 2026-02-06  
**–ê–≤—Ç–æ—Ä**: –†—É—Å–ª–∞–Ω –õ–∞—Ç—ã–ø–æ–≤  
**–ü—Ä–æ–µ–∫—Ç**: Trading Analytics RAG System
